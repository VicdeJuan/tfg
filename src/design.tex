% -*- root: ../main.tex -*-
\chapter{Design\label{chap:design}}

\paragraph{Abstract} 

In this chapter we define the way that formal verification can be achieved, for which first we define some notation and definitions.
%
After some generalities about formal verification, we define more concrete aspects of the formal verification we aim to achieve, such us the linked-list theory used.
%
%
%
\section{Program correctness}
%
We are finally ready to apply this concepts to a real word problem. In this \thisworkm we apply those concepts to prove some properties of programs.
%
The remaining task is to define the framework and the conventions we use to formally prove  properties of programs.

The way we approach to assess correctness is by proving properties. 
%
There are \concept{liveness}, \concept{safety} and \concept{functional} properties. 
%
Safety properties refer, informally, to “bad things never happens”. Proving \textit{ variable x is never 0 } is a safety property. 
%
Proving valid this property can assure that a division by zero error will never occur. 
%
Whether a program finishes or not is a liveness property, and producing an output for a concrete input is a functional property. 

These properties are written in some logic. 
%
Liveness properties require the use of temporal logic but we restrict ourselves to use safety properties so no machinery for temporal properties is needed.
%
As the properties are expressed formally in \gls{FOL}, it is necessary to define a formal representation of a program.


\label{def:SPL}
\input{src/spl}


\subsection{Partial correctness (Safety)}

A function (or the whole program) is \textbf{partially correct} if whenever the function's precondition is satisfied on entry, its postcondition is satisfied when the function returns (if it ever does).
%
We present the \concept{inductive assertion method} for proving partial correctness.


Let $\varphi$ be the \gls{FOL} property to study. 
%
The procedure is the following:
%
First each function is reduced to a finite set of \gls{FOL} formulae called \concept[Verification condition]{\gls{VC}}.
%
This reduction is done with the basic reducing cases we studied in \ref{def:SPL}.
%
The goal is to prove that $\varphi$ is valid in every state of the execution.
%
\textbf{Induction} is the methodology used.
%
First, we assert $\varphi$ is valid before the program starts (induction base).
%
Then, we assume $\varphi$ in the precondition and prove $\varphi'$ valid (induction step) for every possible transition.

This method is not complex to understand but it requires a lot of work even for simple programs. 
%
We illustrate this method with an example in \ref{app:exampleFactorial}.


\section{Parametrized systems}

The correctness of a program executed by just one thread it is an easier problem because the program runs sequentiality.
%
Multiple threads executing the same program is a different and more difficult problem to solve.
%
An unbounded number of threads executing is another important and difficult extension.
%
If the number of threads is bounded, one could unroll the formula for all the threads in the problem. 
%
As this is the usual scenario, we focus the unbounded case.

We are going to study those cases. 
%
To do so, we need to parametrize the program executed by multiple threads.
%
Typically we use  $i$,$j$,$k_0$,$k_i$ for threads identifiers.
%
\subsubsection{Arbitrary number of threads}

For example, the web servers may not have a bound of the number of clients they can accept.
%
Can we prove correctness when an unbounded number of processes are using the same global variables?

A recent research \citeapos{paperParametrizedInvariants} has proven a very important result. 
%
We will present this result new as it is fundamental for this work. 
%
We will not formally prove any of the results proven in \citep{paperParametrizedInvariants}.

Before we enunciate the theorem, we need some previous concepts.
%
We need to extend the concept of support to parametrized formulas.


\begin{defn}[Support]
  Let $\psi$, $A$ and $B$ be parametrized formulas, and let $S$ be the
  set of possible substitutions from the set of parametrized variables in $\psi$ ($\Var(\psi)$) into the set of parametrized variables of $(A\Into B)$ ($\Var(A\Into B)$).
%
  We say that $\psi$ supports $(A\Into B)$, whenever
%
  \[ \big( (\bigwedge_{\sigma\in S} \sigma(\psi)\big) \andcond A\big) \Into B \hspace{4em} \text{is valid} \]
%
  We use $\psi\supports(A\Into B)$ as a short notation for
  $\big((\bigwedge_{\sigma\in S} \sigma(\psi)) \andcond A\big) \Into B$.  
\end{defn}

Note that if $S'\subseteq S$ is a subset of the substitutions, and 
%
  \[ \big( (\bigwedge_{\sigma\in S'} \sigma(\psi)\big) \andcond A\big) \Into B \hspace{4em} \text{is valid} \]
%
then
%
  \[ \big( (\bigwedge_{\sigma\in S} \sigma(\psi)\big) \andcond A\big) \Into B \hspace{4em} \text{is also valid} \]
%
  Essentially, if one succeeds in proving the validity of a formula obtained by removing some of the conjuncts from the antecedent, the validity of the full formula is preserved.
%
  Hence, in practice, it is enough to consider only some of the partial substitutions to show that a support formula is valid.


\begin{itheorem}[Bound an arbitrary number of threads]
	Let $\varphi$ be a thread-parametrized formula, where $\overline{k}=\Var(\varphi)$. 
	%
	Let $\tau$ be a transition of $P$ and $\ThetaParam$ the initial condition of $P$.

	To show that $P$ satisfies $\Always\varphi$ (that is, $\varphi$ is an invariant of $P$):
	\hspace{-1em}
	\[ 
		\begin{array}{r@{\;\;}lr@{\;}@{\;}cl@{\hspace{1em}}l}
			\Premise{S1}. & & \ThetaParam(\overline{k}) &\supports & \varphi & \\

			\Premise{S2}. & \varphi \supports & \tau^{(i)} &\Into& \varphi'  & \text{forall $\tau$ and all $i\in \overline{k}$}\\
			\Premise{S3}. & \varphi\supports & \big(\bigwedge\limits_{x\in\Var(\varphi)} j\neq x \andcond \tau^{(j)} &\Into& \varphi' \big)& \text{forall $\tau$ and one fresh $j\notin\overline{k}$}\\ \hline
			& \multicolumn{4}{c}{\hspace{3em} \Always \varphi} &
		\end{array}
	\]
\label{thm:biggest}
\end{itheorem}



Using this powerful result, we have reduced an arbitrary number of processes sharing the same variables to a finite number of threads sharing the variable. 
%
The proof of this result can be found in \citeapos{paperParametrizedInvariants}.
%
We will refer to $\Premise{S1}$ as \concept{initiation} because it depends on the initial condition.
%
$\Premise{S2}$ will be referred as \concept{self-consecution} because it captures the execution of one of the threads mentioned in the formula.
%
Finally, $\Premise{S3}$ will be referred as \concept{others-consecution} because it captures the execution of threads which do not appear in the formula. 


The example included in appendix \ref{app:exampleFactorial} illustrate the concept of support. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{A Theory of Linked Lists}

\subsection{Description}

In order to work with linked lists in a context with multiple thread using the same list 
there are two possible approaches. 
%
A thread could lock the entire list, work with the list and then release the lock. 
%
There could be some optimizations in this approach, such as a writer-reader system.
%
However, this is extremely \doubt{unefficient} although it could more secure in terms of preventing deadlocks.
%
The other approach is locking and unlocking each node of the list, so multiple threads can work simultaneously using the same list as long as they do not need to use the same node.
%
This approach is called lock-coupling lists.



\begin{defn}[Lock-coupling linked list]
A lock-coupling concurrent list~\cite{herlihy08art,vafeiadis06proving} is 
a concurrent data type that implements a set by maintaining in the heap an 
ordered single-linked list with non-repeating elements.
%
Each node in the list is protected by a lock which guarantees that a 
single thread can access the node at the same time.
%
\end{defn}

The way a thread iterates over the list is the following.
%
The thread acquires the lock of the node
that it visits and after that tries to acquire the next node.
The first lock is only released after the lock of the
second node has been successfully acquired.
%
This technique of protecting cells with locks (instead of protecting
the whole data-structure with a single coarse-grain lock) is known as
\concept{fine-grained locking}.


The nodes of a concurrent lock-coupling list are instances of the following 
\ListNode class:
%
\[
	  \class \;\Node  \;\left\{
				Elem \:\;\; data; \;
				Addr \:\;\; next; \;
				Lock \:\;\; lock; \;
		\right\}
\]
%
Where the fields are:
\begin{itemize}
		\item \fData: the value stored in the node. This field is also used to keep 
			the list ordered.
		\item \fNext: a pointer that stores the address of the next node in 
			the list.
		\item \fLock: the lock protecting the node.
\end{itemize}

We assume that the operating system provides the atomic operations \fLock 
and \fUnlock. 

We will use \concept[Ghost variable]{ghost variables} which are variables that are not present in the program but are added to aid in the verification process.
%
The implementation of concurrent lock-coupling lists has 3 global variables.
%
Two of them are global addresses \head and \tail, and one ghost global variable \region.
%%
The variable \head, an address points to the first node of the list which has the lowest possible value ($-\infty$).
%
The variable \tail, an address points to the last node of the list  which has the lowest possible value ($+\infty$).
%
Finally, the variable \region, a set of addresses, is used to keep track of the portion of the heap whose cells form the list.



In appendix \ref{app:code} we present the program we are going to use, written in \gls{SPL}. 
\todo{The code should be here}
%
There are three procedures, \Search, \Insert and \Remove which traverses through the list the way it was explained.



\subsection{TL3}
To prove verification conditions generated in the proof of invariants of lock-coupling lists we need a theory of lists to work with, and axioms in order to prove \gls{FOL} formulas.

\emph{Theory of Linked Lists with Locks}: \TLLpL, is the theory we use for describing linked-list heap memory layouts.
%
\TLLpL is a multi-sorted first-order theory.
%
It is multi-sorted because it has multiple types for its variables (address, element,...).
%
It is a first-order theory because only variables are quantifiable, as in unsorted \gls{FOL}.

In this section we briefly present \TLLpL. 
%
A more complete and formal definition of \TLLpL can be found in \citeapos{paperAle} and \citep[6.2]{thesisAle}.

Although some functions are originally defined \citep{thesisAle} in suffix notation (\fNext,\fData and \fLock fields), preffix-notation has been used to describe the theory. 
%
The reason for this modification is to be consistent with the syntax of \spass.
%
Furthermore, we use subset of \TLLpL. 
%
In the same way \gls{FOL} can be expressed with $\neg,\vee$ but sometimes $\implies$ is included but $\dimplies$ is not,
%
a few functions of \TLLpL have not been used because they can be expressed using others functions in the theory. 
%
We proceed to describe the subset of \TLLpL used.


\TLLpL is a composition of theories. The \textbf{sorts} used among this theories are: 
%
\cell (representing the nodes of the list),
%
\elem (representing elements),
%
\addr (representing address),
%
\tid (representing thread id),
%
\mem (representing the memory also called heap, represented as maps of \addr to \cell ),
%
\path (representing a finite sequence of address),
%
\sSetTid, \sSetAddr, \sSetElem to represent sets of \tid,\addr or \elem respectively.

For each sort, there is a theory containing its constants, functions and predicates. 
%
There is one more theory, $\Sigma_{Bridge}$ is a \emph{bridge theory} containing auxiliary
functions, for example, that allow to map paths of addresses to set of 
addresses, or to obtain the set of addresses reachable from a given 
address following a chain of \fNext fields.



\subsection{Signature}

We proceed to describe the signature of each theory, listing the sorts used and explaining its functions, predicates and constants. 
%
Every theory includes the equality theory \ref{theory:equality} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%					TID 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{center}\rule{4cm}{0.4pt} $\Sigma_{\tid}$ \rule{4cm}{0.4pt}\end{center}
\paragraph{$\Sigma_{\tid}$ : }
%
The sort used is \tid. The “no-thread” value is represented with \fNoThread.
%
Apart from the equality theory, this theory does not have any other predicates or functions.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%					ELEM

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\begin{center}\rule{4cm}{0.4pt} $\Sigma_{\elem}$ \rule{4cm}{0.4pt}\end{center}
\paragraph{$\Sigma_{\elem}$ : }
%
The sort used is \elem. 
%
There is a total order which allows to order every set of \elem.
%
In addition, this sort is upper and lower bounded.
%
 The top block contains the functions and the lower block lists the predicates.

\begin{center}
\begin{tabular}{|rrl|}
  \hline
\fHighest & \elem & Maximum value an \elem can take.\\
\fLowest & \elem & Minimum value an \elem can take.\\
\hline\hline
\fLselem & \elem$\times$\elem & Total order relation between \elem.
\\\hline
\end{tabular}
%\caption{\textbf{Signature of $\Sigma_{\ensuremath{\mathit{elem}}}$.} The top block contains the functions and the lower block lists the predicates.}
%\label{table:elem_signature}
\end{center}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%					CELL

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{center}\rule{4cm}{0.4pt} $\Sigma_{\cell}$ \rule{4cm}{0.4pt}\end{center}
\paragraph{$\Sigma_{\cell}$ : }
%
The sorts used are \cell,\;\elem,\;\addr,\;\tid.

\begin{center}
\begin{tabular}{|rrl|}
  \hline
\fMkcell & $\elem\times\addr\times\tid \to \cell$ & Constructor\\
\fNext & $\cell \to \addr$ & Getter of \fNext field \\ 
\fData & $\cell \to \elem$ & Getter of \fData field \\ 
\fLockID & $\cell \to \tid$ & Getter of \fLockID field \\ 
\fLock & $\cell\times\tid\to\cell$ & Construct a new \cell with \fData and \fNext \\
&&\;\;\;								values of the given \cell, \\
&&\;\;\;				using the \tid for the \fLockID field.\\
\fError & $\cell$ & Constant value used to model \\ 
&&\;\;\;				incorrect memory deference.
\\\hline
\end{tabular}
%\caption{\textbf{Functions of $\Sigma_{\cell}$} theory.}
%\label{table:cell_signature}
\end{center}

The function \fUnlock could be considered. Actually, \cite{thesisAle} includes it in the theory but it has not been included in this work.
%
The reason is justified because to \fUnlock a \cell is equivalent to \fLock a \cell with \fNoThread value.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%					MEMORY

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\begin{center}\rule{4cm}{0.4pt} $\Sigma_{\mem}$ \rule{4cm}{0.4pt}\end{center}
\paragraph{$\Sigma_{\mem}$ : }
%
The sorts used are \mem,\cell and \addr. 

\begin{center}
\begin{tabular}{|rrl|}
  \hline
\fNull & $\addr$ & Null address \\
\fRd & $\mem\times\addr\to\cell$ & Models memory deference. \\
&&								\;\;\; Returns the value from the \mem the \cell \\
&&								\;\;\; stored in the \addr.\\
\fUpd & $\mem\times\addr\times\cell\to\mem$ & Creates a new \mem from the given one
\\\hline
\end{tabular}
%\caption{\textbf{Functions of $\Sigma_{\mem}$} theory}
\label{table:memory_signature}
\end{center}

A function related with \mem theory is \fMalloc, used in the \insertprg procedure.
%
The function \fMalloc does not belongs to \gls{SPL} or \TLLpL but it can be translated as a conjunction of assignments and assignments are allowed in both theories.
%
The function \fMalloc returns a new fresh address different to every other address in use, so the \freshaddr returned by \fMalloc is not equal to \head, nor \tail, etc.
%
\fMalloc formal representation correspond to a big conjunction of all the formulas stating \freshaddr is not equal to \addr, for all \addr appearing in the formula (except itself).
%\[\forall x,y. [x\neq y \andcond x=\fMalloc(h) \implies h(x)\neq h(y)]\]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%					SETADDR

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\begin{center}\rule{4cm}{0.4pt} $\Sigma_{\sSetAddr}$ \rule{4cm}{0.4pt}\end{center}
\paragraph{$\Sigma_{\sSetAddr}$ : }
%
It models the usual set theory. 
%
We preferred a prefix version of each function and predicate to be consistent with Section \ref{ax::fulllist}.
%


The intersection function and the subset predicate have not been included, even tough \citep{thesisAle} uses them. 
%
They were not used because they were redundant.

\begin{center}
\begin{tabular}{|rrl|}
  \hline
\fEmptyset & \sSetAddr & Empty set\\
\fSingl & $\addr\to\sSetAddr $& Constructor of a single-element set.\\
\fUnion & $\sSetAddr\times\sSetAddr\to\sSetAddr$&\\
\fSetdiff & $\sSetAddr\times\sSetAddr\to\sSetAddr$&\\
\hline\hline
\pIn & $\sAddr\times\sSetAddr $& 
\\\hline
\end{tabular}
%\caption{\textbf{Signature of $\Sigma_{\sSetAddr}$.} The top block contains the functions and the lower block lists the predicates.}
\label{table:setaddr_signature}
\end{center}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%					SETELEM

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\begin{center}\rule{4cm}{0.4pt} $\Sigma_{\sSetElem}$ \rule{4cm}{0.4pt}\end{center}
\paragraph{$\Sigma_{\sSetElem}$ : }
%
Again, it models the usual set theory.
%
The signature is described in Table \ref{table:setelem_signature}.

\begin{center}
\begin{tabular}{|rrl|}
  \hline
\fEmptysetElem & $\sSet $& Empty set\\
\fSinglElem & $\elem\to\sSet $& Constructor of a single-element set.\\
\fUnionElem & $\sSet\times\sSet\to\sSet$&\\
\fSetdiffElem & $\sSet\times\sSet\to\sSet$&\\
\hline\hline
\pInElem & $\sAddr\times\sSet $& 
\\\hline
\end{tabular}
%\caption{\textbf{Signature of $\Sigma_{\sSetElem}$.} The top block contains the functions and the lower block lists the predicates.}
\label{table:setelem_signature}
\end{center}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%					SETTID

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\begin{center}\rule{4cm}{0.4pt} $\Sigma_{\sSetTid}$ \rule{4cm}{0.4pt}\end{center}
\paragraph{$\Sigma_{\sSetTid}$ : }
%
The signature is described in Table \ref{table:settid_signature}.

\begin{center}
\begin{tabular}{|rrl|}
  \hline
\fEmptysetTid & $\sSetAddr $& Empty set\\
\fSinglTid & $\addr\to\sSetAddr $& Constructor of a single-element set.\\
\fUnionTid & $\sSetAddr\times\sSetAddr\to\sSetAddr$&\\
\fSetdiffTid & $\sSetAddr\times\sSetAddr\to\sSetAddr$&\\
\hline\hline
\pInTid & $\sAddr\times\sSetAddr$ &
\\\hline
\end{tabular}
%\caption{\textbf{Signature of $\Sigma_{\sSetAddr}$.} The top block contains the functions and the lower block lists the predicates.}
\label{table:settid_signature}
\end{center}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%					BRIDGE

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\begin{center}\rule{4cm}{0.4pt} $\Sigma_{Bridge}$ \rule{4cm}{0.4pt}\end{center}
\paragraph{$\Sigma_{Bridge}$ : }
%
This theory is much more extensive in \cite{thesisAle}. 
%
However, aiming for simplicity, we do not include every function and predicate because we do not use them in our proofs. 
%
The only function used in the proofs is:
\begin{center}
\begin{tabular}{|rrl|}
  \hline
\fAddrToSet & $\mem\times\addr\to\sSetAddr $& Returns the set of \addr reachable from the \addr given.\\
\hline
\end{tabular}
%\caption{\textbf{Signature of $\Sigma_{\sSetAddr}$.}}
\label{table:bridge_signature}
\end{center}



